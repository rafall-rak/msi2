{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fetching and preprocessing the MNIST dataset",
   "id": "fcdc34fe7211caf1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = X.values\n",
    "X = X / 255.\n",
    "y = y.astype(int).values\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ],
   "id": "b4a754d5533ecec4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualize the first digit of each class:",
   "id": "6f902b4b83aecfc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = X[y == i][0].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "7d40a88f95bcd1c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualize 25 different versions of \"7\":",
   "id": "70973fe6ca422660"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_, ax = plt.subplots(nrows=5, ncols=5, sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for i in range(25):\n",
    "    img = X[y == 7][i].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f137f4ebcbc00646",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Split into training, validation, and test set:",
   "id": "436996890432f725"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=10000, random_state=123, stratify=y)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_temp, y_temp, test_size=5000, random_state=123, stratify=y_temp)\n",
    "\n",
    "# free up some memory by deleting non-used arrays:\n",
    "del X_temp, y_temp, X, y"
   ],
   "id": "25f03fbc8d2d4410",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Multi-layer perceptron",
   "id": "eb8f3148856b1089"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1. / (1. + np.exp(-z))\n",
    "\n",
    "\n",
    "def int_to_onehot(y, num_labels):\n",
    "    ary = np.zeros((y.shape[0], num_labels))\n",
    "    for i, val in enumerate(y):\n",
    "        ary[i, val] = 1\n",
    "\n",
    "    return ary"
   ],
   "id": "ef84c8438fa82122",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class NeuralNetMLP:\n",
    "\n",
    "    def __init__(self, num_features, num_hidden, num_classes, random_seed=123):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        rng = np.random.RandomState(random_seed)\n",
    "\n",
    "        self.weight_h = rng.normal(loc=0.0, scale=0.1, size=(num_hidden, num_features))\n",
    "        self.bias_h = np.zeros(num_hidden)\n",
    "\n",
    "        self.weight_out = rng.normal(loc=0.0, scale=0.1, size=(num_classes, num_hidden))\n",
    "        self.bias_out = np.zeros(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_h = np.dot(x, self.weight_h.T) + self.bias_h\n",
    "        a_h = sigmoid(z_h)\n",
    "\n",
    "        z_out = np.dot(a_h, self.weight_out.T) + self.bias_out\n",
    "        a_out = sigmoid(z_out)\n",
    "        return a_h, a_out\n",
    "\n",
    "    def backward(self, x, a_h, a_out, y):\n",
    "        y_onehot = int_to_onehot(y, self.num_classes)\n",
    "\n",
    "        d_loss__d_a_out = 2. * (a_out - y_onehot) / y.shape[0]\n",
    "        d_a_out__d_z_out = a_out * (1. - a_out)  # sigmoid derivative\n",
    "        delta_out = d_loss__d_a_out * d_a_out__d_z_out  # to be reused\n",
    "        d_z_out__dw_out = a_h\n",
    "\n",
    "        d_loss__dw_out = np.dot(delta_out.T, d_z_out__dw_out)\n",
    "        d_loss__db_out = np.sum(delta_out, axis=0)\n",
    "\n",
    "        d_z_out__a_h = self.weight_out\n",
    "        d_loss__a_h = np.dot(delta_out, d_z_out__a_h)\n",
    "        d_a_h__d_z_h = a_h * (1. - a_h)  # sigmoid derivative\n",
    "        d_z_h__d_w_h = x\n",
    "\n",
    "        d_loss__d_w_h = np.dot((d_loss__a_h * d_a_h__d_z_h).T, d_z_h__d_w_h)\n",
    "        d_loss__d_b_h = np.sum((d_loss__a_h * d_a_h__d_z_h), axis=0)\n",
    "\n",
    "        return d_loss__dw_out, d_loss__db_out, d_loss__d_w_h, d_loss__d_b_h"
   ],
   "id": "ee6d7801ad0eaae3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = NeuralNetMLP(num_features=28 * 28,\n",
    "                     num_hidden=50,\n",
    "                     num_classes=10)"
   ],
   "id": "a411b082b20bc8b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The trenning loop:",
   "id": "87e29544d69dd50b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def minibatch_generator(X, y, minibatch_size):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    for start_idx in range(0, indices.shape[0] - minibatch_size + 1, minibatch_size):\n",
    "        batch_idx = indices[start_idx:start_idx + minibatch_size]\n",
    "\n",
    "        yield X[batch_idx], y[batch_idx]"
   ],
   "id": "7dc8d26598075584",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Just to check the mini-batch generator...",
   "id": "91a6e212f77bc330"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_epochs = 80\n",
    "minibatch_size = 100\n",
    "X_train_mini, y_train_mini = None, None\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    minibatch_gen = minibatch_generator(X_train, y_train, minibatch_size)\n",
    "\n",
    "    for X_train_mini, y_train_mini in minibatch_gen:\n",
    "        break\n",
    "\n",
    "    break\n",
    "\n",
    "print(X_train_mini.shape)\n",
    "print(y_train_mini.shape)"
   ],
   "id": "c114f57833001231",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Loss and accuracy",
   "id": "ed414f6dfb36bc51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def mse_loss(targets, probas, num_labels=10):\n",
    "    onehot_targets = int_to_onehot(targets, num_labels=num_labels)\n",
    "    return np.mean((onehot_targets - probas) ** 2)\n",
    "\n",
    "\n",
    "def accuracy(targets, predicted_labels):\n",
    "    return np.mean(predicted_labels == targets)"
   ],
   "id": "6d3692baef9e1dc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_, probas = model.forward(X_valid)\n",
    "mse = mse_loss(y_valid, probas)\n",
    "\n",
    "predicted_labels = np.argmax(probas, axis=1)\n",
    "acc = accuracy(y_valid, predicted_labels)\n",
    "\n",
    "print(f'Initial validation MSE: {mse:.1f}')\n",
    "print(f'Initial validation accuracy: {acc * 100:.1f}%')"
   ],
   "id": "81668115c765a57c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_mse_and_acc(nnet, X, y, num_labels=10, minibatch_size=100):\n",
    "    mse, correct_pred, num_examples = 0., 0, 0\n",
    "    minibatch_gen = minibatch_generator(X, y, minibatch_size)\n",
    "\n",
    "    n_i = 0\n",
    "    for i, (features, targets) in enumerate(minibatch_gen):\n",
    "        _, probas = nnet.forward(features)\n",
    "        predicted_labels: np.ndarray = np.argmax(probas, axis=1)\n",
    "\n",
    "        onehot_targets = int_to_onehot(targets, num_labels=num_labels)\n",
    "        loss = np.mean((onehot_targets - probas) ** 2)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "\n",
    "        num_examples += targets.shape[0]\n",
    "        mse += loss\n",
    "        n_i = i\n",
    "\n",
    "    mse = mse / (n_i + 1)\n",
    "    acc = correct_pred / num_examples\n",
    "    return mse, acc"
   ],
   "id": "2dcb3e276b3308ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mse, acc = compute_mse_and_acc(model, X_valid, y_valid)\n",
    "print(f'Initial valid MSE: {mse:.1f}')\n",
    "print(f'Initial valid accuracy: {acc * 100:.1f}%')"
   ],
   "id": "f9056fd54ef90ae0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train(model, X_train, y_train, X_valid, y_valid, num_epochs, learning_rate=0.1):\n",
    "    epoch_loss = []\n",
    "    epoch_train_acc = []\n",
    "    epoch_valid_acc = []\n",
    "\n",
    "    for e in range(num_epochs):\n",
    "        minibatch_gen = minibatch_generator(X_train, y_train, minibatch_size)\n",
    "\n",
    "        for X_train_mini, y_train_mini in minibatch_gen:\n",
    "            a_h, a_out = model.forward(X_train_mini)\n",
    "\n",
    "            d_loss__d_w_out, d_loss__d_b_out, d_loss__d_w_h, d_loss__d_b_h = \\\n",
    "                model.backward(X_train_mini, a_h, a_out, y_train_mini)\n",
    "\n",
    "            model.weight_h -= learning_rate * d_loss__d_w_h\n",
    "            model.bias_h -= learning_rate * d_loss__d_b_h\n",
    "            model.weight_out -= learning_rate * d_loss__d_w_out\n",
    "            model.bias_out -= learning_rate * d_loss__d_b_out\n",
    "\n",
    "        train_mse, train_acc = compute_mse_and_acc(model, X_train, y_train)\n",
    "        valid_mse, valid_acc = compute_mse_and_acc(model, X_valid, y_valid)\n",
    "        train_acc, valid_acc = train_acc * 100, valid_acc * 100\n",
    "        epoch_train_acc.append(train_acc)\n",
    "        epoch_valid_acc.append(valid_acc)\n",
    "        epoch_loss.append(train_mse)\n",
    "        print(f'Epoch: {e + 1:03d}/{num_epochs:03d} '\n",
    "              f'| Train MSE: {train_mse:.2f} '\n",
    "              f'| Train Acc: {train_acc:.2f}% '\n",
    "              f'| Valid Acc: {valid_acc:.2f}%')\n",
    "\n",
    "    return epoch_loss, epoch_train_acc, epoch_valid_acc"
   ],
   "id": "4dae387d63a66d25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.random.seed(123)  # for the training set shuffling\n",
    "\n",
    "epoch_loss, epoch_train_acc, epoch_valid_acc = train(\n",
    "    model, X_train, y_train, X_valid, y_valid,\n",
    "    num_epochs=50, learning_rate=0.1)"
   ],
   "id": "4082486b8c165df5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluating the NN performance",
   "id": "be9b52b92e364024"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(range(len(epoch_loss)), epoch_loss)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ],
   "id": "814319ce5d9b3ae1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(range(len(epoch_train_acc)), epoch_train_acc,\n",
    "         label='Training')\n",
    "plt.plot(range(len(epoch_valid_acc)), epoch_valid_acc,\n",
    "         label='Validation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ],
   "id": "264dedbb026db4cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_mse, test_acc = compute_mse_and_acc(model, X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')"
   ],
   "id": "689ab039b6560179",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Failure cases:",
   "id": "a064ad4e39cfc63a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_test_subset = X_test[:1000, :]\n",
    "y_test_subset = y_test[:1000]\n",
    "\n",
    "_, probas = model.forward(X_test_subset)\n",
    "test_pred = np.argmax(probas, axis=1)\n",
    "\n",
    "misclassified_images = X_test_subset[y_test_subset != test_pred][:25]\n",
    "misclassified_labels = test_pred[y_test_subset != test_pred][:25]\n",
    "correct_labels = y_test_subset[y_test_subset != test_pred][:25]"
   ],
   "id": "b5d8e3b1d19383cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_, ax = plt.subplots(nrows=5, ncols=5,\n",
    "                     sharex=True, sharey=True, figsize=(8, 8))\n",
    "ax = ax.flatten()\n",
    "for i in range(25):\n",
    "    img = misclassified_images[i].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "    ax[i].set_title(f'{i + 1}) '\n",
    "                    f'True: {correct_labels[i]}\\n'\n",
    "                    f' Predicted: {misclassified_labels[i]}')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cb53abdf19005934",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
