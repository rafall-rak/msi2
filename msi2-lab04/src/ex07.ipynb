{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. A linear regression model - a simple example, a low-level approach",
   "id": "8231a92e5b84d39"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train = np.arange(10, dtype='float32').reshape((10, 1))\n",
    "y_train = np.array([1.0, 1.3, 3.1, 2.0, 5.0, 6.3, 6.6, 7.4, 8.0, 9.0], dtype='float32')\n",
    "\n",
    "plt.plot(X_train, y_train, 'o', markersize=10)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.show()"
   ],
   "id": "2d2cb6ba5bd09148",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "\n",
    "X_train_norm = torch.from_numpy(std_scaler.transform(X_train))\n",
    "y_train = torch.from_numpy(y_train)  # note: the explicit cast to .float() may be necessary\n",
    "\n",
    "train_ds = TensorDataset(X_train_norm, y_train)\n",
    "\n",
    "batch_size = 1\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ],
   "id": "4fdcb33849b95a5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def loss_fn(inp, target):\n",
    "    return (inp - target).pow(2).mean()\n",
    "\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weight + bias"
   ],
   "id": "9f4535528df39ef4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1)\n",
    "weight = torch.randn(1)\n",
    "weight.requires_grad_()\n",
    "bias = torch.zeros(1, requires_grad=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 200\n",
    "log_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = torch.tensor(0.0)  # it is accessed outside the internal loop\n",
    "\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            weight -= weight.grad * learning_rate\n",
    "            bias -= bias.grad * learning_rate\n",
    "            weight.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "\n",
    "    if epoch % log_epochs == 0:\n",
    "        print(f'Epoch {epoch} Loss {loss.item():.4f}')\n"
   ],
   "id": "cedaa6a84d8d2892",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print('Final Parameters:', weight.item(), bias.item())",
   "id": "b8f71f9b05ddb13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_test = np.linspace(0, 9, num=100, dtype='float32').reshape(-1, 1)\n",
    "X_test_norm = torch.from_numpy(std_scaler.transform(X_test))\n",
    "\n",
    "y_pred = model(X_test_norm).detach().numpy()"
   ],
   "id": "216e6eeb1084471e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.plot(X_train_norm, y_train, 'o', markersize=10)\n",
    "plt.plot(X_test_norm, y_pred, '--', lw=3)\n",
    "plt.legend(['Training examples', 'Linear Reg.'], fontsize=15)\n",
    "ax.set_xlabel('x', size=15)\n",
    "ax.set_ylabel('y', size=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.show()"
   ],
   "id": "2a3ec91d5c58db89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. A linear regression model - a simple example, torch.nn and torch.optim based approach",
   "id": "d12976dfb492f47e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ],
   "id": "f66e61e8e33b95c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for epoch in range(num_epochs):\n",
    "    loss = torch.tensor(0.0)  # it is accessed outside the internal loop\n",
    "\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        # 1. Generate predictions\n",
    "        pred = model(x_batch)[:, 0]\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "\n",
    "        # 3. Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # 4. Update parameters using gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # 5. Reset the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    if epoch % log_epochs == 0:\n",
    "        print(f'Epoch {epoch}  Loss {loss.item():.4f}')"
   ],
   "id": "8601af5839279f81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print('Final Parameters:', model.weight.item(), model.bias.item())",
   "id": "38f4b5413d4723a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_test = np.linspace(0, 9, num=100, dtype='float32').reshape(-1, 1)\n",
    "X_test_norm = torch.from_numpy(std_scaler.transform(X_test))\n",
    "y_pred = model(X_test_norm)"
   ],
   "id": "9dd9145ca9779c60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.plot(X_train_norm.detach().numpy(), y_train.detach().numpy(), 'o', markersize=10)\n",
    "plt.plot(X_test_norm.detach().numpy(), y_pred.detach().numpy(), '--', lw=3)\n",
    "plt.legend(['Training examples', 'Linear reg.'], fontsize=15)\n",
    "ax.set_xlabel('x', size=15)\n",
    "ax.set_ylabel('y', size=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.show()"
   ],
   "id": "9284ef0f26db68a5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
